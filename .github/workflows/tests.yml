name: continuous-integration

on: [push, pull_request]

env:
  COVERAGE_THRESHOLD: 60

jobs:

  lint:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8]

    steps:
    - uses: actions/checkout@v2

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python-version }}

    - name: Set up Node/yarn
      uses: actions/setup-node@v1
      with:
        node-version: '10.x'

    - name: Cache python wheels
      uses: actions/cache@v2
      with:
        path: ~/.cache/pip
        key: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('setup.py', 'docs/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Cache node_modules
      uses: actions/cache@v2
      with:
        path: 'node_modules'
        key: |
          ${{ runner.os }}-node-modules-${{ hashFiles('yarn.lock') }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        python -m pip install --upgrade pre-commit
        python -m pip install -e .
        yarn --frozen-lockfile

    - name: Lint
      run: |
        pre-commit run --all-files

  # Build docs on a number of Python versions. In the future this can be
  # where tests go.
  tests:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.6, 3.7, 3.8]

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache python wheels
      uses: actions/cache@v2
      with:
        path: ~/.cache/pip
        key: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('setup.py', 'docs/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        python -m pip install -e .[coverage]

    # Build the docs
    - name: Build docs to store
      run: |
        export PATH="$HOME/miniconda/bin:$PATH"
        sphinx-build -b html docs/ docs/_build/html -W --keep-going

    # Run tests under coverage
    - name: Run the tests
      run: pytest --cov pydata_sphinx_theme --cov-branch --cov-report term-missing:skip-covered --cov-fail-under ${{ env.COVERAGE_THRESHOLD }}

    - name: Upload coverage
      if: ${{ always() }}
      run: codecov

  # Run local Lighthouse audit against built site
  audit:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8]
    env:
      PORT: 8000
      # the host interface to listen on, might need to be 0.0.0.0
      HOST: 127.0.0.1
      # the base url
      URL: http://127.0.0.1:8000

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache python wheels
      uses: actions/cache@v2
      with:
        path: ~/.cache/pip
        key: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('setup.py', 'docs/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip wheel setuptools
        python -m pip install -e .[coverage]

    # Build the docs
    - name: Build docs to store
      run: |
        export PATH="$HOME/miniconda/bin:$PATH"
        sphinx-build -b html docs/ docs/_build/html -W --keep-going

    # Serve the docs and wait to be ready
    - name: Serve the built site
      run: |
        nohup python docs/serve.py --port=${PORT} --host=${HOST} &
        curl --retry 10 --retry-connrefused --retry-max-time 60 ${URL}/index.html

    # Run the audit
    # TODO: use the hosted API with a secret? would allow for comparison over time...
    - name: Make folder for Lighthouse reports
      run: mkdir -p /tmp/lighthouse/lighthouse-${{ github.run_number }}
    - name: Run Lighthouse on Site
      id: lighthouse
      uses: foo-software/lighthouse-check-action@v2.0.0
      with:
        # TODO: generate this list to audit all html pages
        urls: >-
          ${{ env.URL }}/index.html,
          ${{ env.URL }}/demo/api.html,
          ${{ env.URL }}/demo/demo.html,
          ${{ env.URL }}/demo/example_pandas.html
        outputDirectory: /tmp/lighthouse/lighthouse-${{ github.run_number }}
        verbose: true

    # Store the audit
    - name: Upload Lighthouse Reports
      uses: actions/upload-artifact@v2
      with:
        name: Lighthouse Report ${{ github.run_number }}
        path: /tmp/lighthouse

    # Check the audit for threshold values
    # TODO: write this someplace after a PR is merged, and load?
    - name: Assess Lighthouse Check results
      uses: foo-software/lighthouse-check-status-action@v1.0.1
      with:
        lighthouseCheckResults: ${{ steps.lighthouse.outputs.lighthouseCheckResults }}
        minAccessibilityScore: "96"
        minBestPracticesScore: "85"
        minPerformanceScore: "10"
        minSeoScore: "80"

  publish:

    name: Publish to PyPi
    needs: [lint, tests]
    if: github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v2
      - name: Set up Python 3.7
        uses: actions/setup-python@v1
        with:
          python-version: 3.7
      - name: Build package
        run: |
          python -m pip install -U pip setuptools wheel
          python setup.py sdist bdist_wheel
      - name: Publish
        uses: pypa/gh-action-pypi-publish@v1.1.0
        with:
          user: __token__
          password: ${{ secrets.PYPI_KEY }}
